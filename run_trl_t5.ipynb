{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01bdbf-03bd-4c5c-a30b-a74d08537945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets==2.9.0 transformers==4.26.1 seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52499e8d-590d-4ec3-b2f2-8f1a0f7b16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flax jax==0.4.2 jaxlib==0.4.2+cuda11.cudnn86 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1294be-00da-4695-b0db-219f6002d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 convert_t5x_checkpoint_to_flax.py \\\n",
    "#     --t5x_checkpoint_path out/chemprot/biot5x_base_text/checkpoint_1204500 \\\n",
    "#     --config_name t5_base_config.json \\\n",
    "#     --flax_dump_folder_path out/chemprot/biot5_flax_text\n",
    "\n",
    "\n",
    "# from transformers import AutoModel, T5TokenizerFast\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"out/chemprot/biot5_flax_text\", from_flax=True)\n",
    "# tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "\n",
    "# model.save_pretrained(\"trl/out/chemprot_hf/biot5_pytorch_text\")\n",
    "# tokenizer.save_pretrained(\"trl/out/chemprot_hf/biot5_pytorch_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065e358-ec8e-4a64-8863-1ed619fcb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"trl/out/chemprot_hf/biot5_pytorch_text\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"trl/out/chemprot_hf/biot5_pytorch_text\")\n",
    "\n",
    "\n",
    "model.push_to_hub(\"justinphan3110/biot5_chemprot\")\n",
    "tokenizer.push_to_hub(\"justinphan3110/biot5_chemprot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502090be-0d95-45e9-bd06-0facfdce033b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['MODEL']='SciFive-base-Pubmed_PMC'\n",
    "# os.environ['MODEL_PATH']=f\"razent/{os.environ['MODEL']}\"\n",
    "\n",
    "os.environ['MODEL']='biot5x_base_hf'\n",
    "os.environ['MODEL_PATH']=f\"out/{os.environ['MODEL']}\"\n",
    "\n",
    "os.environ['task']='chemprot'\n",
    "os.environ['datadir']=f\"biot5x/data/{os.environ['task']}\"\n",
    "os.environ['outdir']=f\"out/tmp/{os.environ['task']}_hf/{os.environ['MODEL']}\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "  # --save_strategy epoch --evaluation_strategy epoch --load_best_model_at_end --metric_for_best_model F1  \\\n",
    "\n",
    "!python3 -u run_scifive_hf.py --model_name_or_path $MODEL_PATH \\\n",
    "  --train_file $datadir/train_blurb.tsv --validation_file $datadir/test_blurb.tsv --test_file $datadir/test_blurb.tsv \\\n",
    "  --do_train --do_predict --metric_name PRF1 --predict_with_generate \\\n",
    "  --per_device_train_batch_size 128 --per_device_eval_batch_size 128 --fp16_full_eval --gradient_accumulation_steps 1 --fp16 \\\n",
    "  --learning_rate 0.0005 --num_train_epochs 40 --max_source_length 256 --max_target_length 4 \\\n",
    "  --log_level warning --output_dir $outdir --overwrite_output_dir --from_flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78079148-e763-44a8-83ce-ed20e49eb019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2ba45-3d60-45be-8f12-82ca04122390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out/chemprot_hf/biot5_pytorch_text\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ['MODEL']='biot5_pytorch_text'\n",
    "# os.environ['MODEL_PATH']=f\"trl/out/chemprot_hf/{os.environ['MODEL']}\"\n",
    "\n",
    "\n",
    "os.environ['MODEL']='biot5_chemprot'\n",
    "os.environ['MODEL_PATH']=f\"justinphan3110/{os.environ['MODEL']}\"\n",
    "os.environ['task']='chemprot'\n",
    "os.environ['datadir']=f\"biot5x/data/{os.environ['task']}\"\n",
    "os.environ['outdir']=f\"tmp/{os.environ['task']}_hf/{os.environ['MODEL']}\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "  # --save_strategy epoch --evaluation_strategy epoch --load_best_model_at_end --metric_for_best_model F1  \\\n",
    "\n",
    "!python3 -u run_scifive_hf.py --model_name_or_path $MODEL_PATH \\\n",
    "  --train_file $datadir/train_blurb.tsv --validation_file $datadir/test_blurb.tsv --test_file $datadir/test_blurb_text.tsv \\\n",
    "  --do_predict --metric_name PRF1 --predict_with_generate \\\n",
    "  --per_device_train_batch_size 128 --per_device_eval_batch_size 128 --fp16_full_eval --gradient_accumulation_steps 1 --fp16 \\\n",
    "  --learning_rate 0.00005 --num_train_epochs 20 --max_source_length 256 --max_target_length 5 \\\n",
    "  --log_level warning --output_dir $outdir --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38661b-874f-423e-8dd1-a1b5eef9ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MODEL']='checkpoint_2'\n",
    "os.environ['MODEL_PATH']=f\"trl/out/test_trl_biot5_chemprot/{os.environ['MODEL']}\"\n",
    "os.environ['task']='chemprot'\n",
    "os.environ['datadir']=f\"biot5x/data/{os.environ['task']}\"\n",
    "os.environ['outdir']=f\"tmp/{os.environ['task']}_hf/{os.environ['MODEL']}\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "  # --save_strategy epoch --evaluation_strategy epoch --load_best_model_at_end --metric_for_best_model F1  \\\n",
    "\n",
    "!python3 -u run_scifive_hf.py --model_name_or_path $MODEL_PATH \\\n",
    "  --train_file $datadir/train_blurb.tsv --validation_file $datadir/test_blurb.tsv --test_file $datadir/test_blurb_text.tsv \\\n",
    "  --do_predict --metric_name PRF1 --predict_with_generate \\\n",
    "  --per_device_train_batch_size 512 --per_device_eval_batch_size 512 --fp16_full_eval --gradient_accumulation_steps 1 --fp16 \\\n",
    "  --learning_rate 0.00005 --num_train_epochs 20 --max_source_length 256 --max_target_length 5 \\\n",
    "  --log_level warning --output_dir $outdir --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d2bed-59e0-43b7-9188-cbb9bcafaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MODEL']='biot5x'\n",
    "os.environ['MODEL_PATH']=f\"out/ddi_hf/{os.environ['MODEL']}\"\n",
    "os.environ['task']='ddi'\n",
    "os.environ['datadir']=f\"biot5x/data/{os.environ['task']}\"\n",
    "os.environ['outdir']=f\"out/{os.environ['task']}_hf/{os.environ['MODEL']}\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "  # --save_strategy epoch --evaluation_strategy epoch --load_best_model_at_end --metric_for_best_model F1  \\\n",
    "\n",
    "!python3 -u run_scifive_hf.py --model_name_or_path $MODEL_PATH \\\n",
    "  --train_file $datadir/train_blurb.tsv --validation_file $datadir/test_blurb.tsv --test_file $datadir/test_blurb.tsv \\\n",
    "  --do_predict --metric_name PRF1 --predict_with_generate \\\n",
    "  --per_device_train_batch_size 128 --per_device_eval_batch_size 128 --fp16_full_eval --gradient_accumulation_steps 1 --fp16 \\\n",
    "  --learning_rate 0.00005 --num_train_epochs 20 --max_source_length 256 --max_target_length 4 \\\n",
    "  --log_level warning --output_dir $outdir --overwrite_output_dir --from_flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85962b4-e07a-4f5c-9e20-689d5f76d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
